---
title: "Advanced Machine Learning for GIS and Land Cover Estimation "
subtitle: "Random Forest Model on GIS file (extracted by Blanca)"
author: "Christophe Bontemps (SIAP)"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  html_document:
    code_folding: show
    toc: yes
    toc_float: true
    highlight: tango
    number_sections: no
    theme: lumen
  word_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set( message = FALSE, warning = FALSE, results =FALSE, echo = TRUE) 
```

# Installing the packages

```{r packages}
# File management
library(readxl)


# GIS packages
library(raster) ## for reading "RASTER" files
library(rgdal)  ## for reading "shapefiles"
library(sp)     ## for adjusting CRS in 
library(terra)  ## see https://www.neonscience.org/resources/learning-hub/tutorials/image-raster-data-r

# Tidy data management packages
library(dplyr)
library(data.table)
library(modelsummary)
library(ggcorrplot)
library(forcats)

# Model fitting packages for ML
library(rpart)
library(caret)


# Plotting packages
library(ggplot2)
library(RColorBrewer)

# Nice presentation of results
library(knitr)
library(papeR)

# My colors:
SIAP.color <- "#0385a8"
SIAP.red <- "#eb4034"

```


# Importing the Satelite images

There are many data sources freely available with environmental information at a very detailed level. These files are from huge data bases that cover large areas of the word. 


## a. Importing the stack of images

```{r}
# import stacked raster (img) 
library(sf)

img <- brick("Data/GISBlanca/stack_raster123456788A91112_MayJune2020.tif")
```
 
These are images taken with different bands and reflecting the nature of waves coming back from the satellite sensors. 

```{r}
plot(img)
```


##  b. Importing the shapefiles with  ground truth land classes

```{r}
# Importing Shapefiles
shp <- read_sf("Data/GISBlanca/reference_dataset_ROIs/")

# extract classes and band information and put in a dataframe for later
names(img) <- c("b1", "b2", "b3", "b4", "b5", "b6", "b7", "b8", "b8A", "b9", "b11", "b12")
```

## c. Matching the information from Raster (bands) with class values on the ground 

```{r}
DataForModel <- extract(img, shp, df = TRUE)

# Creating class for each location 
DataForModel$class <- as.factor(shp$MC_ID[match(DataForModel$ID, seq(nrow(shp)))])

# We need a numeric variable as well 
DataForModel <- DataForModel %>%
   mutate(classnum = as.numeric(class))

# DO NOT USE
# It is easy to do mistakes and have categories mismatched as below!  
# The code below is not correct

# DataForModel <- left_join(DataForModel, shp, join_by("classnum"=="MC_ID"))
# DataForModel <- DataForModel %>%
#   select(-c("ID", "fid", "C_name", "C_ID", "SCP_UID", "geometry", "class")) %>%
#   mutate(class = as.factor(MC_name))
```


We have now a data frame `DataForModel`with `r nrow(DataForModel)` observations. The data frame contains the land cover classification variable `class`  to predict, and several explanatory variables or *predictors*  `b1, b2, ...b12`.

## Summary statistics

```{r}
# Let us define the classes with their names instead of numbers

# Define the class labels
class_labels <- c(
  "1" = "Dense_vegetation",
  "2" = "Pastureland_grassland",
  "3" = "Other_vegetation", 
  "4" = "Built-up", 
  "5" = "Water",
  "6" = "Reef", 
  "7" = "Cloud"
)

# We affect labels as defined by class_labels, to the variable class
DataForModel$class <- factor(DataForModel$class, levels = names(class_labels), labels = class_labels)

```


```{r, echo = TRUE}
datasummary_skim(as.factor(DataForModel$class) , type = "categorical" , 
                 notes = paste("N =", nrow(DataForModel)) )

```


```{r, echo = TRUE}
# Graphic
DataForModel %>%
mutate(class = fct_infreq(class) %>% fct_rev()) %>%  # Reorder and reverse factor levels
ggplot() + 
  geom_bar(aes(y = class), colour="white", fill = SIAP.color) +
  theme_minimal() + 
  theme(plot.title = element_text(hjust = 0.5))+ 
  labs(x = "", y = "") +
  ggtitle("Land types ")
```




## Predictors 
We define the list of explanatory variables (or *predictors*) 

```{r}
# Define the subset of variables (here X1, X, .., X8B, ...X12)
predictor_vars <- DataForModel %>%
  select(starts_with("b")) %>%
  names()

predictor_vars

```


```{r, results=TRUE, echo=TRUE}
datasummary_skim(select(DataForModel, predictor_vars) ,   type = "numeric",
                 title = "Full data set (DataForModel)",
                notes = paste("N =", nrow(DataForModel)) )
```


# Explanatory variables analysis



```{r}
# We compute the correlation matrix of the covariates
corr_coef<-cor(DataForModel[, predictor_vars], use = "p")

#And then plot it with nice options 
ggcorrplot(corr_coef, 
           type = "lower",         # lower triangle of the matrix only
           #hc.order = TRUE,        # variable sorted from highest to lowest
           outline.col = "white",  #Color options
           lab = TRUE)
```


The data preparation & validation methods ends here, so letâ€™s process to machine learning models.

# Machine learning


## Train and Validation data sets

```{r }
# Splits data into training and testing sets
set.seed(007)
# We'll randomly pick some observation from the full data set

trainIndex <- createDataPartition(DataForModel$class, p = .80, 
                                  list = FALSE, 
                                  times = 1)

# Creating the two data sets: 
train_data <- DataForModel[ trainIndex,]
validation_data  <- DataForModel[-trainIndex,]

```


We have `r nrow(train_data)` observations in the training data set (80\%) and `r nrow(validation_data)` observations in the validation data set (20\%). It is important to have a look at our train data set and check if it has the same characteristics, in particular for the categories distribution.  

```{r,  results= TRUE }
datasummary_skim(train_data$class , type = "categorical",
                 title = "Train data set",
                 notes = paste("N =", nrow(train_data))) 
```

##  Missing values in the training data set

```{r}
# see https://rpubs.com/NguyenKhanh20/1069336

anyNA(train_data)
```

> We do **not**  have missing values for any variables. 


##  Selecting Cross Validation parameters

```{r, include = FALSE, echo = FALSE}
# function to set up random seeds when running on several cores 
#  (you do not need to understand that)

setSeeds <- function(method = "cv", numbers = 1, repeats = 1, tunes = NULL, seed = 2512) {
  #B is the number of resamples and integer vector of M (numbers + tune length if any)
  B <- if (method == "cv") numbers
  else if(method == "repeatedcv") numbers * repeats
  else NULL
  
  if(is.null(length)) {
    seeds <- NULL
  } else {
    set.seed(seed = seed)
    seeds <- vector(mode = "list", length = B)
    seeds <- lapply(seeds, function(x) sample.int(n = 1000000, size = numbers + ifelse(is.null(tunes), 0, tunes)))
    seeds[[length(seeds) + 1]] <- sample.int(n = 1000000, size = 1)
  }
  # return seeds
  seeds
}

```

```{r}
# Summary function with six statistics of interest 
# sixStats <- function(...) c(twoClassSummary(...), 
#                             defaultSummary(...))
```

By default, repeated K-fold cross-validation is used here. The function `r `trainControl` can be used to specify the type of resampling. We use here K= 5 and 10 repetition of the process. We then estimate 5 x 10 = 50 different predictions.

```{r controls}

# control variables (see later)
K <- 5
Myrepeats <- 10
rcvTunes <- 1 # tune number of models
Myseed <- 2512

```


##  Random Forest

We begin with fitting a Random Forest model using cross-validation on the *Training* data set 

Random Forest is a *bagging* (*bootstrap aggregation*) method. During training a bootstrap sample is drawn from the training data together with a subset of the total amount of variables, we then pick the best available variable to split the tree into two daughter nodes repeatedly until we reach a stopping criterion. This process is repeated until we have trained as many individual decision trees as we want. We can then combine the output of the decision trees into one final output.

Our final output will be based on the **majority vote** of the individual decision trees. 


```{r, include = FALSE}
# Repeated cross validation
rcvSeeds <- setSeeds(method = "repeatedcv", 
                      numbers = K,
                      repeats = Myrepeats, 
                      tunes = 100,
                      seed = Myseed)


# Configure the trainControl argument for cross-validation
K5_CV_seed <- trainControl(method = "cv", 
                           number = K,
                           classProbs = FALSE, 
                           savePredictions = TRUE,
                           seeds = rcvSeeds,
                           allowParallel = TRUE)

```


###  Training the model on selected variables 

We can decide to train the model on all the explanatory variables (using  `.` as right-hand side of the formula as below) or an only a subset of the variables that are available to us:

* So using all variables would write  `rf_fit <- train(class ~ . ,  ... `
* Alternatively, we could use a `formula`  and write `rf_fit <- train(formula, ... `

For more flexibility, we use that second option here

```{r}
# And the formula becomes
formula <- as.formula(paste("class ~", paste(predictor_vars, collapse = " + ")))
```

> Our `formula` is now `r paste("class ~", paste(predictor_vars, collapse = " + "))`  

And we can train our model: 

```{r, cache = FALSE}
# Train your model using the subset of variables
rf_fit <- train(formula,
                data = train_data,
                method = "rf",
                ntree = 100,
                trControl = K5_CV_seed)
```


```{r, results=TRUE}
rf_fit
```
## Playing with parameters for the RF model 

The package used `caret` allows a lot of testing for the "right" choice of parameters affecting random forest models.  In particular `mtry`  and `ntree`. Let us change these parameters and see how this affects our model accuracy 


### The number of variables used for each node of each tree `mtry`
By default, `caret`does a minimal search of 3 different numbers for `mtry` and selects the one that maximize accuracy. Let's change that parameter to do an extensive **grid search** up to the maximum possible. 
 
 > Here the maximum number is 11 (12-1),  since we have "only" 12 predictor and we need at least one! 
 
```{r}
rf_fit <- train(formula,
                data = train_data,
                method = "rf",
                ntree = 100,
                tuneLength = 11, #  <- computes for 12 values of mtry
                metric= "Kappa",  # we can choose the criteria (Kappa vs Accuracy)
                trControl = K5_CV_seed)
                
                
```

```{r, results=TRUE}
rf_fit
```

```{r}
plot(rf_fit)
# One can also plot the graphic with a different metric in mind.! 
#plot(rf_fit, metric ="Kappa")

```

### The number of trees  used `ntree`


```{r}
rf_fit <- train(formula,
                data = train_data,
                method = "rf",
                ntree = 10,
                trControl = K5_CV_seed)
                
                
```

```{r, results=TRUE}
rf_fit
```

```{r}
plot(rf_fit)
```




### Evaluating Model Performance 

We can assess the quality of the model both *in sample*, that is how well the model estimates the data within the training data set  and *out of sample* performance, where we compare predictions based on a validation data set ("*unseen data*"). 

### The *in sample* performance is:

```{r, results=TRUE}
rf_pred <- predict(rf_fit, train_data)
# length(rf_pred)

# Confusion, matrix
 confusionMatrix(rf_pred, train_data$class)
```


We need now further investigation to see if the model generalizes well or if it just has learned from the training data. The high accuracy is a symptom of overfitting.

### Variable importance

```{r}
GISVarImportance<- varImp(rf_fit, scale = FALSE)
plot(GISVarImportance)
```

### The *Out of sample* performance 


```{r, results=TRUE}
rf_pred_Valid <- predict(rf_fit, validation_data)
rf_CM <- confusionMatrix(rf_pred_Valid, validation_data$class)
rf_CM
```

### Predicted classification on the validation sample

Our validation sample has **`r nrow(validation_data)`** observations. Let's see how the prediction goes on these points: 


```{r}
pred_valid <-as.data.frame(rf_pred_Valid) 

datasummary_skim(pred_valid , type = "categorical",
                 title = "Prediction",
                 notes = paste("N =", nrow(pred_valid))) 
```

## Logistic model

As for the random forest model, we fist train our model on the `train_data` subsample. The Random forets model 


```{r, cache = FALSE}

# Train your model using the training data set

logi_fit <- train(formula,
                data = train_data,
                method = "multinom", 
                trControl = K5_CV_seed,
                trace = FALSE)
logi_fit
            
```

### The *in sample* performance is:

```{r, results=TRUE}
logi_pred <- predict(logi_fit, train_data)

# Confusion, matrix
confusionMatrix(logi_pred, train_data$class)
```

We need now further investigation to see if the model generalizes well or if it just has learned from the training data. 

### Variable importance


```{r}
LogiVarImportance<- varImp(logi_fit, scale = FALSE)
plot(LogiVarImportance)
```


### The *Out of sample* performance 


```{r, results=TRUE}
logi_pred_Valid <- predict(logi_fit, validation_data)
logi_CM <- confusionMatrix(logi_pred_Valid, validation_data$class)
logi_CM
```

# Predictions on the whole area

We now take the whole image and predict on all pixels using the model that we estimated. 

## Predictions with *Random Forest*

```{r}
# prediction with Random Forest model
rf_result <- predict(img,
                  rf_fit,
                  filename = "Data/GISBlanca/classification_fromRF.tif",
                  overwrite = TRUE
                  )  

```


```{r,  results= TRUE }
Table_result <- as.data.frame(rf_result) %>%
  mutate(class =  as.factor(classification_fromRF))

# We affect labels as defined by class_labels, to the variable class
Table_result$class <- factor(Table_result$class, levels = names(class_labels), labels = class_labels)

# Table_result <- left_join(Table_result, shp, join_by("classification_fromR"=="MC_ID")) %>%
#   mutate(class = as.factor(MC_name)) %>%
#  select(-c( "fid", "C_name", "MC_name", "C_ID", "SCP_UID", "geometry")) 
```


```{r,  results= TRUE }
datasummary_skim(Table_result , type = "categorical",
                 title = "Prediction on the whole region",
                 notes = paste("N =", nrow(Table_result))) 
```


```{r}
# Graphic
Table_result %>%
mutate(class = fct_infreq(class) %>% fct_rev()) %>%  # Reorder and reverse factor levels
ggplot() + 
  geom_bar(aes(y = class), colour="white", fill = SIAP.color) +
  theme_minimal() + 
  theme(plot.title = element_text(hjust = 0.5))+ 
  labs(x = "", y = "", subtitle = paste ( "Random Forest model. N= ", nrow(Table_result)))  +
  ggtitle("Land types predicted on the whole area ")
```
## Predictions with *Multinomial Logistic*

```{r}
# prediction with Multinomial Logistic  
logi_result <- predict(img,
                  logi_fit,
                  filename = "Data/GISBlanca/classification_fromlogi.tif",
                  overwrite = TRUE
                  )  

```


```{r,  results= TRUE }
Table_result_logi <- as.data.frame(logi_result) %>%
  mutate(class =  as.factor(classification_fromlogi))

# We affect labels as defined by class_labels, to the variable class
Table_result_logi$class <- factor(Table_result_logi$class, levels = names(class_labels), labels = class_labels)


```


```{r,  results= TRUE }
datasummary_skim(Table_result_logi , type = "categorical",
                 title = "Prediction on the whole region",
                 notes = paste("N =", nrow(Table_result_logi))) 
```


```{r}
# Graphic
Table_result_logi %>%
mutate(class = fct_infreq(class) %>% fct_rev()) %>%  # Reorder and reverse factor levels
ggplot() + 
  geom_bar(aes(y = class), colour="white", fill = SIAP.color) +
  theme_minimal() + 
  theme(plot.title = element_text(hjust = 0.5))+ 
  labs(x = "", y = "", subtitle = paste ( "Multinomial Logistic model. N= ", nrow(Table_result_logi)))  +
  ggtitle("Land types predicted on the whole area ")
```



## Visualizing the predictions  on the map


```{r}
# Load necessary libraries
library(terra)

# Read the TIFF file from the Random forest model
raster_data <- rast("Data/GISBlanca/classification_fromRF.tif")

# Convert the raster to a data frame for ggplot2
raster_df_RF <- as.data.frame(raster_data, xy = TRUE)


# define the color palette associated with classes
class_colors <- c(
   "darkgreen",     # Dense vegetation
  "#DEB887",        # Pastureland/grassland
  "#339933",        # Other vegetation
  "#e60000",        # "Built-up", 
  "darkblue",        # Water
  "lightblue",      # Reef
  "darkgrey"            # Cloud
)


# Convert raster values to a factor with labels
raster_df_RF$classification_fromRF <- factor(raster_df_RF$classification_fromRF, levels = names(class_labels), labels = class_labels)
```



```{r}
# Plot using ggplot2
p_RF <- ggplot() +
  geom_raster(data = raster_df_RF, aes(x = x, y = y, fill = classification_fromRF), alpha = 0.5 ) +
  scale_fill_manual(values = class_colors, name = "Land Cover") +
  coord_fixed() +
  theme_minimal() +
  labs(title = "Prediction (with RF) ",
       subtitle = paste("Out-of-sample accuracy was ", as.character(round(rf_CM$overall[1], 4)) ), 
       caption =  paste ( "N= ", nrow(raster_df_RF)),
       x = "Longitude",
       y = "Latitude")
# Plot
p_RF

```




```{r}
# Read the TIFF file from the Multinomial logistic  model
raster_data_logi<- rast("Data/GISBlanca/classification_fromlogi.tif")

# Convert the raster to a data frame for ggplot2
raster_df_logi <- as.data.frame(raster_data_logi, xy = TRUE)

# Convert raster values to a factor with labels
raster_df_logi$classification_fromlogi <- factor(raster_df_logi$classification_fromlogi, levels = names(class_labels), labels = class_labels)
```



```{r}
# Plot using ggplot2
p_logi <- ggplot() +
  geom_raster(data = raster_df_logi, aes(x = x, y = y, fill = classification_fromlogi), alpha = 0.5 ) +
  scale_fill_manual(values = class_colors, name = "Land Cover") +
  coord_fixed() +
  theme_minimal() +
  labs(title = "Prediction (MNL) ",
       subtitle = paste("Out-of-sample accuracy was ", as.character(round(logi_CM$overall[1], 4)) ), 
       caption =  paste ( "N= ", nrow(raster_df_logi)),
       x = "Longitude",
       y = "Latitude")
# Plot
p_logi

```


```{r}
library("patchwork")
# Combine the plots
# removing the legend for one plot 
p_RF <- p_RF + theme(legend.position = "none")
p_logi <- p_logi + theme(legend.position = "none")


RFvslogi <- (p_RF |  p_logi) 

# Display the combined plot
print(RFvslogi)
```
```{r}
# Merge the data frames on x and y coordinates
combined_df <- raster_df_RF %>%
  inner_join(raster_df_logi, by = c("x", "y")) %>%
  rename(prediction_RF = classification_fromRF, prediction_logi = classification_fromlogi)

# Create a new column indicating whether the predictions are the same or different
combined_df <- combined_df %>%
  mutate(diff = ifelse(prediction_RF == prediction_logi, "No Change", "Change")) %>%
  mutate(diff_class = ifelse(prediction_RF == prediction_logi, prediction_RF, "8"))


# Define the  augmented color class labels with the category "Difference" 
class_labels_N <- c(class_labels, "8" = "Difference")

# Define the augmented color palette accordingly 
class_colors_N <- c(class_colors, "white")


# Convert raster values to a factor with labels
combined_df$diff_class <- factor(combined_df$diff_class, levels = names(class_labels_N), labels = class_labels_N)

#Plot the map highlighting changes
p_diff <- ggplot(combined_df, aes(x = x, y = y)) +
  geom_raster(aes(fill = diff_class)) +
 scale_fill_manual(values = class_colors_N, name = "Land Cover") +
  coord_fixed() +
  theme_minimal() +
  labs(title = "Predictions differences",
       subtitle = "RF predictions vs MNL predictions",
       x = "Longitude", y = "Latitude")

p_diff

```

### Statistics on the differences 

> How important are the differences between the 2 models? 

```{r}
nb_diff <- combined_df %>%
  filter(diff=="Change") %>%
  nrow()
pc_diff <- round(100 * nb_diff / nrow(combined_df),2)
```


```{r}
combined_df %>%
  filter(diff=="Change") %>%
  mutate(prediction_RF = fct_infreq(prediction_RF) %>% fct_rev()) %>%  # Reorder and reverse factor levels
  ggplot() + 
  geom_bar(aes(y = prediction_RF), colour="white", fill = SIAP.color,) +
  theme_minimal() + 
  theme(plot.title = element_text(hjust = 0.5))+ 
  labs(x = "", y = "", 
       subtitle = paste ( "N= ", nrow(combined_df %>% filter(diff=="Change")), "differences (", pc_diff, "% )")
       )  +
  ggtitle("Which categories have more differences?  ")
  

```

### Comparing with QGIS (Random Forest model)

```{r}

# Read the TIFF file
raster_RF_QGIS <- rast("Data/GISBlanca/R_RF_Classification_2020.tif")

# Convert the raster to a data frame for ggplot2
raster_df_QGIS <- as.data.frame(raster_RF_QGIS, xy = TRUE)

# Convert raster values to a factor with labels
raster_df_QGIS$R_RF_Classification_2020 <- factor(raster_df_QGIS$R_RF_Classification_2020, levels = names(class_labels), labels = class_labels)


# Plot using ggplot2
p_QGIS <- ggplot() +
  geom_raster(data = raster_df_QGIS, aes(x = x, y = y, fill = R_RF_Classification_2020), alpha = 0.5 ) +
  scale_fill_manual(values = class_colors, name = "Land Cover") +
  coord_fixed() +
  theme_minimal() +
  labs(title = "Prediction (with QGIS) ",
       x = "Longitude",
       y = "Latitude")

p_QGIS

```

### Visualizing the differences

```{r}
# Computing the differences

# Merge the data frames on x and y coordinates
combined_df <- combined_df %>%
  inner_join(raster_df_QGIS, by = c("x", "y")) %>%
  rename(prediction_QGIS = R_RF_Classification_2020)

# Create a new column indicating whether the predictions are the same or different
combined_df <- combined_df %>%
  mutate(diff_Q = ifelse(prediction_RF == prediction_QGIS, "No Change", "Change"))%>%
   mutate(diff_class_Q = ifelse(prediction_RF ==prediction_QGIS, prediction_RF, "8"))

# Convert raster values to a factor with labels
combined_df$diff_class_Q <- factor(combined_df$diff_class_Q, levels = names(class_labels_N), labels = class_labels_N)


```


```{r}

#Plot the map highlighting changes
p_full <- ggplot(combined_df, aes(x = x, y = y)) +
  geom_raster(aes(fill = diff_class_Q ), alpha = 0.5 ) +
 scale_fill_manual(values = class_colors_N, name = "Land Cover") +
  coord_fixed() +
  theme_minimal() +
  labs(title = "Predictions differences",
       subtitle = "R predictions vs QGIS predictions",
       x = "Longitude", y = "Latitude")

p_full

```



```{r}
knit_exit()
```



### Statistics on the differences 

```{r}
nb_diff <- combined_df_C %>%
  filter(diff=="Change") %>%
  nrow()
pc_diff <- round(100 * nb_diff / nrow(combined_df_C),2)
```


```{r}
combined_df_C %>%
  filter(diff=="Change") %>%
  mutate(prediction_RF = fct_infreq(prediction_RF) %>% fct_rev()) %>%  # Reorder and reverse factor levels
  ggplot() + 
  geom_bar(aes(y = prediction_RF), colour="white", fill = SIAP.color,) +
  theme_minimal() + 
  theme(plot.title = element_text(hjust = 0.5))+ 
  labs(x = "", y = "", 
       subtitle = paste ( "N= ", nrow(combined_df_C %>% filter(diff=="Change")), "differences (", pc_diff, "% )")
       )  +
  ggtitle("Which categories have more differences?  ")
  

```




```{r}
library("patchwork")
# Combine the plots
# removing the legend for one plot 
p_RF <- p_RF + theme(legend.position = "none")
p_QGIS <- p_QGIS + theme(legend.position = "none")
p_diff <- p_diff + theme(legend.position = "none")
p_full <- p_full + theme(legend.position = "bottom")

combined_plot <- (p_RF |  p_QGIS) / (p_diff + p_full)  

# Display the combined plot
print(combined_plot)
```


```{r}
knit_exit()
```

